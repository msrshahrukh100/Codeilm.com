{"ast":null,"code":"// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/LICENSE\n(function (mod) {\n  if (typeof exports == \"object\" && typeof module == \"object\") // CommonJS\n    mod(require(\"../../lib/codemirror\"), require(\"../css/css\"));else if (typeof define == \"function\" && define.amd) // AMD\n    define([\"../../lib/codemirror\", \"../css/css\"], mod);else // Plain browser env\n    mod(CodeMirror);\n})(function (CodeMirror) {\n  \"use strict\";\n\n  CodeMirror.defineMode(\"sass\", function (config) {\n    var cssMode = CodeMirror.mimeModes[\"text/css\"];\n    var propertyKeywords = cssMode.propertyKeywords || {},\n        colorKeywords = cssMode.colorKeywords || {},\n        valueKeywords = cssMode.valueKeywords || {},\n        fontProperties = cssMode.fontProperties || {};\n\n    function tokenRegexp(words) {\n      return new RegExp(\"^\" + words.join(\"|\"));\n    }\n\n    var keywords = [\"true\", \"false\", \"null\", \"auto\"];\n    var keywordsRegexp = new RegExp(\"^\" + keywords.join(\"|\"));\n    var operators = [\"\\\\(\", \"\\\\)\", \"=\", \">\", \"<\", \"==\", \">=\", \"<=\", \"\\\\+\", \"-\", \"\\\\!=\", \"/\", \"\\\\*\", \"%\", \"and\", \"or\", \"not\", \";\", \"\\\\{\", \"\\\\}\", \":\"];\n    var opRegexp = tokenRegexp(operators);\n    var pseudoElementsRegexp = /^::?[a-zA-Z_][\\w\\-]*/;\n    var word;\n\n    function isEndLine(stream) {\n      return !stream.peek() || stream.match(/\\s+$/, false);\n    }\n\n    function urlTokens(stream, state) {\n      var ch = stream.peek();\n\n      if (ch === \")\") {\n        stream.next();\n        state.tokenizer = tokenBase;\n        return \"operator\";\n      } else if (ch === \"(\") {\n        stream.next();\n        stream.eatSpace();\n        return \"operator\";\n      } else if (ch === \"'\" || ch === '\"') {\n        state.tokenizer = buildStringTokenizer(stream.next());\n        return \"string\";\n      } else {\n        state.tokenizer = buildStringTokenizer(\")\", false);\n        return \"string\";\n      }\n    }\n\n    function comment(indentation, multiLine) {\n      return function (stream, state) {\n        if (stream.sol() && stream.indentation() <= indentation) {\n          state.tokenizer = tokenBase;\n          return tokenBase(stream, state);\n        }\n\n        if (multiLine && stream.skipTo(\"*/\")) {\n          stream.next();\n          stream.next();\n          state.tokenizer = tokenBase;\n        } else {\n          stream.skipToEnd();\n        }\n\n        return \"comment\";\n      };\n    }\n\n    function buildStringTokenizer(quote, greedy) {\n      if (greedy == null) {\n        greedy = true;\n      }\n\n      function stringTokenizer(stream, state) {\n        var nextChar = stream.next();\n        var peekChar = stream.peek();\n        var previousChar = stream.string.charAt(stream.pos - 2);\n        var endingString = nextChar !== \"\\\\\" && peekChar === quote || nextChar === quote && previousChar !== \"\\\\\";\n\n        if (endingString) {\n          if (nextChar !== quote && greedy) {\n            stream.next();\n          }\n\n          if (isEndLine(stream)) {\n            state.cursorHalf = 0;\n          }\n\n          state.tokenizer = tokenBase;\n          return \"string\";\n        } else if (nextChar === \"#\" && peekChar === \"{\") {\n          state.tokenizer = buildInterpolationTokenizer(stringTokenizer);\n          stream.next();\n          return \"operator\";\n        } else {\n          return \"string\";\n        }\n      }\n\n      return stringTokenizer;\n    }\n\n    function buildInterpolationTokenizer(currentTokenizer) {\n      return function (stream, state) {\n        if (stream.peek() === \"}\") {\n          stream.next();\n          state.tokenizer = currentTokenizer;\n          return \"operator\";\n        } else {\n          return tokenBase(stream, state);\n        }\n      };\n    }\n\n    function indent(state) {\n      if (state.indentCount == 0) {\n        state.indentCount++;\n        var lastScopeOffset = state.scopes[0].offset;\n        var currentOffset = lastScopeOffset + config.indentUnit;\n        state.scopes.unshift({\n          offset: currentOffset\n        });\n      }\n    }\n\n    function dedent(state) {\n      if (state.scopes.length == 1) return;\n      state.scopes.shift();\n    }\n\n    function tokenBase(stream, state) {\n      var ch = stream.peek(); // Comment\n\n      if (stream.match(\"/*\")) {\n        state.tokenizer = comment(stream.indentation(), true);\n        return state.tokenizer(stream, state);\n      }\n\n      if (stream.match(\"//\")) {\n        state.tokenizer = comment(stream.indentation(), false);\n        return state.tokenizer(stream, state);\n      } // Interpolation\n\n\n      if (stream.match(\"#{\")) {\n        state.tokenizer = buildInterpolationTokenizer(tokenBase);\n        return \"operator\";\n      } // Strings\n\n\n      if (ch === '\"' || ch === \"'\") {\n        stream.next();\n        state.tokenizer = buildStringTokenizer(ch);\n        return \"string\";\n      }\n\n      if (!state.cursorHalf) {\n        // state.cursorHalf === 0\n        // first half i.e. before : for key-value pairs\n        // including selectors\n        if (ch === \"-\") {\n          if (stream.match(/^-\\w+-/)) {\n            return \"meta\";\n          }\n        }\n\n        if (ch === \".\") {\n          stream.next();\n\n          if (stream.match(/^[\\w-]+/)) {\n            indent(state);\n            return \"qualifier\";\n          } else if (stream.peek() === \"#\") {\n            indent(state);\n            return \"tag\";\n          }\n        }\n\n        if (ch === \"#\") {\n          stream.next(); // ID selectors\n\n          if (stream.match(/^[\\w-]+/)) {\n            indent(state);\n            return \"builtin\";\n          }\n\n          if (stream.peek() === \"#\") {\n            indent(state);\n            return \"tag\";\n          }\n        } // Variables\n\n\n        if (ch === \"$\") {\n          stream.next();\n          stream.eatWhile(/[\\w-]/);\n          return \"variable-2\";\n        } // Numbers\n\n\n        if (stream.match(/^-?[0-9\\.]+/)) return \"number\"; // Units\n\n        if (stream.match(/^(px|em|in)\\b/)) return \"unit\";\n        if (stream.match(keywordsRegexp)) return \"keyword\";\n\n        if (stream.match(/^url/) && stream.peek() === \"(\") {\n          state.tokenizer = urlTokens;\n          return \"atom\";\n        }\n\n        if (ch === \"=\") {\n          // Match shortcut mixin definition\n          if (stream.match(/^=[\\w-]+/)) {\n            indent(state);\n            return \"meta\";\n          }\n        }\n\n        if (ch === \"+\") {\n          // Match shortcut mixin definition\n          if (stream.match(/^\\+[\\w-]+/)) {\n            return \"variable-3\";\n          }\n        }\n\n        if (ch === \"@\") {\n          if (stream.match(/@extend/)) {\n            if (!stream.match(/\\s*[\\w]/)) dedent(state);\n          }\n        } // Indent Directives\n\n\n        if (stream.match(/^@(else if|if|media|else|for|each|while|mixin|function)/)) {\n          indent(state);\n          return \"def\";\n        } // Other Directives\n\n\n        if (ch === \"@\") {\n          stream.next();\n          stream.eatWhile(/[\\w-]/);\n          return \"def\";\n        }\n\n        if (stream.eatWhile(/[\\w-]/)) {\n          if (stream.match(/ *: *[\\w-\\+\\$#!\\(\"']/, false)) {\n            word = stream.current().toLowerCase();\n            var prop = state.prevProp + \"-\" + word;\n\n            if (propertyKeywords.hasOwnProperty(prop)) {\n              return \"property\";\n            } else if (propertyKeywords.hasOwnProperty(word)) {\n              state.prevProp = word;\n              return \"property\";\n            } else if (fontProperties.hasOwnProperty(word)) {\n              return \"property\";\n            }\n\n            return \"tag\";\n          } else if (stream.match(/ *:/, false)) {\n            indent(state);\n            state.cursorHalf = 1;\n            state.prevProp = stream.current().toLowerCase();\n            return \"property\";\n          } else if (stream.match(/ *,/, false)) {\n            return \"tag\";\n          } else {\n            indent(state);\n            return \"tag\";\n          }\n        }\n\n        if (ch === \":\") {\n          if (stream.match(pseudoElementsRegexp)) {\n            // could be a pseudo-element\n            return \"variable-3\";\n          }\n\n          stream.next();\n          state.cursorHalf = 1;\n          return \"operator\";\n        }\n      } // cursorHalf===0 ends here\n      else {\n          if (ch === \"#\") {\n            stream.next(); // Hex numbers\n\n            if (stream.match(/[0-9a-fA-F]{6}|[0-9a-fA-F]{3}/)) {\n              if (isEndLine(stream)) {\n                state.cursorHalf = 0;\n              }\n\n              return \"number\";\n            }\n          } // Numbers\n\n\n          if (stream.match(/^-?[0-9\\.]+/)) {\n            if (isEndLine(stream)) {\n              state.cursorHalf = 0;\n            }\n\n            return \"number\";\n          } // Units\n\n\n          if (stream.match(/^(px|em|in)\\b/)) {\n            if (isEndLine(stream)) {\n              state.cursorHalf = 0;\n            }\n\n            return \"unit\";\n          }\n\n          if (stream.match(keywordsRegexp)) {\n            if (isEndLine(stream)) {\n              state.cursorHalf = 0;\n            }\n\n            return \"keyword\";\n          }\n\n          if (stream.match(/^url/) && stream.peek() === \"(\") {\n            state.tokenizer = urlTokens;\n\n            if (isEndLine(stream)) {\n              state.cursorHalf = 0;\n            }\n\n            return \"atom\";\n          } // Variables\n\n\n          if (ch === \"$\") {\n            stream.next();\n            stream.eatWhile(/[\\w-]/);\n\n            if (isEndLine(stream)) {\n              state.cursorHalf = 0;\n            }\n\n            return \"variable-2\";\n          } // bang character for !important, !default, etc.\n\n\n          if (ch === \"!\") {\n            stream.next();\n            state.cursorHalf = 0;\n            return stream.match(/^[\\w]+/) ? \"keyword\" : \"operator\";\n          }\n\n          if (stream.match(opRegexp)) {\n            if (isEndLine(stream)) {\n              state.cursorHalf = 0;\n            }\n\n            return \"operator\";\n          } // attributes\n\n\n          if (stream.eatWhile(/[\\w-]/)) {\n            if (isEndLine(stream)) {\n              state.cursorHalf = 0;\n            }\n\n            word = stream.current().toLowerCase();\n\n            if (valueKeywords.hasOwnProperty(word)) {\n              return \"atom\";\n            } else if (colorKeywords.hasOwnProperty(word)) {\n              return \"keyword\";\n            } else if (propertyKeywords.hasOwnProperty(word)) {\n              state.prevProp = stream.current().toLowerCase();\n              return \"property\";\n            } else {\n              return \"tag\";\n            }\n          } //stream.eatSpace();\n\n\n          if (isEndLine(stream)) {\n            state.cursorHalf = 0;\n            return null;\n          }\n        } // else ends here\n\n\n      if (stream.match(opRegexp)) return \"operator\"; // If we haven't returned by now, we move 1 character\n      // and return an error\n\n      stream.next();\n      return null;\n    }\n\n    function tokenLexer(stream, state) {\n      if (stream.sol()) state.indentCount = 0;\n      var style = state.tokenizer(stream, state);\n      var current = stream.current();\n\n      if (current === \"@return\" || current === \"}\") {\n        dedent(state);\n      }\n\n      if (style !== null) {\n        var startOfToken = stream.pos - current.length;\n        var withCurrentIndent = startOfToken + config.indentUnit * state.indentCount;\n        var newScopes = [];\n\n        for (var i = 0; i < state.scopes.length; i++) {\n          var scope = state.scopes[i];\n          if (scope.offset <= withCurrentIndent) newScopes.push(scope);\n        }\n\n        state.scopes = newScopes;\n      }\n\n      return style;\n    }\n\n    return {\n      startState: function startState() {\n        return {\n          tokenizer: tokenBase,\n          scopes: [{\n            offset: 0,\n            type: \"sass\"\n          }],\n          indentCount: 0,\n          cursorHalf: 0,\n          // cursor half tells us if cursor lies after (1)\n          // or before (0) colon (well... more or less)\n          definedVars: [],\n          definedMixins: []\n        };\n      },\n      token: function token(stream, state) {\n        var style = tokenLexer(stream, state);\n        state.lastToken = {\n          style: style,\n          content: stream.current()\n        };\n        return style;\n      },\n      indent: function indent(state) {\n        return state.scopes[0].offset;\n      }\n    };\n  }, \"css\");\n  CodeMirror.defineMIME(\"text/x-sass\", \"sass\");\n});","map":null,"metadata":{},"sourceType":"script"}