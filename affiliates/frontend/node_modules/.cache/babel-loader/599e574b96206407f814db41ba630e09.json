{"ast":null,"code":"// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: https://codemirror.net/LICENSE\n(function (mod) {\n  if (typeof exports == \"object\" && typeof module == \"object\") // CommonJS\n    mod(require(\"../../lib/codemirror\"));else if (typeof define == \"function\" && define.amd) // AMD\n    define([\"../../lib/codemirror\"], mod);else // Plain browser env\n    mod(CodeMirror);\n})(function (CodeMirror) {\n  \"use strict\";\n\n  CodeMirror.defineMode(\"crystal\", function (config) {\n    function wordRegExp(words, end) {\n      return new RegExp((end ? \"\" : \"^\") + \"(?:\" + words.join(\"|\") + \")\" + (end ? \"$\" : \"\\\\b\"));\n    }\n\n    function chain(tokenize, stream, state) {\n      state.tokenize.push(tokenize);\n      return tokenize(stream, state);\n    }\n\n    var operators = /^(?:[-+/%|&^]|\\*\\*?|[<>]{2})/;\n    var conditionalOperators = /^(?:[=!]~|===|<=>|[<>=!]=?|[|&]{2}|~)/;\n    var indexingOperators = /^(?:\\[\\][?=]?)/;\n    var anotherOperators = /^(?:\\.(?:\\.{2})?|->|[?:])/;\n    var idents = /^[a-z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\n    var types = /^[A-Z_\\u009F-\\uFFFF][a-zA-Z0-9_\\u009F-\\uFFFF]*/;\n    var keywords = wordRegExp([\"abstract\", \"alias\", \"as\", \"asm\", \"begin\", \"break\", \"case\", \"class\", \"def\", \"do\", \"else\", \"elsif\", \"end\", \"ensure\", \"enum\", \"extend\", \"for\", \"fun\", \"if\", \"include\", \"instance_sizeof\", \"lib\", \"macro\", \"module\", \"next\", \"of\", \"out\", \"pointerof\", \"private\", \"protected\", \"rescue\", \"return\", \"require\", \"select\", \"sizeof\", \"struct\", \"super\", \"then\", \"type\", \"typeof\", \"uninitialized\", \"union\", \"unless\", \"until\", \"when\", \"while\", \"with\", \"yield\", \"__DIR__\", \"__END_LINE__\", \"__FILE__\", \"__LINE__\"]);\n    var atomWords = wordRegExp([\"true\", \"false\", \"nil\", \"self\"]);\n    var indentKeywordsArray = [\"def\", \"fun\", \"macro\", \"class\", \"module\", \"struct\", \"lib\", \"enum\", \"union\", \"do\", \"for\"];\n    var indentKeywords = wordRegExp(indentKeywordsArray);\n    var indentExpressionKeywordsArray = [\"if\", \"unless\", \"case\", \"while\", \"until\", \"begin\", \"then\"];\n    var indentExpressionKeywords = wordRegExp(indentExpressionKeywordsArray);\n    var dedentKeywordsArray = [\"end\", \"else\", \"elsif\", \"rescue\", \"ensure\"];\n    var dedentKeywords = wordRegExp(dedentKeywordsArray);\n    var dedentPunctualsArray = [\"\\\\)\", \"\\\\}\", \"\\\\]\"];\n    var dedentPunctuals = new RegExp(\"^(?:\" + dedentPunctualsArray.join(\"|\") + \")$\");\n    var nextTokenizer = {\n      \"def\": tokenFollowIdent,\n      \"fun\": tokenFollowIdent,\n      \"macro\": tokenMacroDef,\n      \"class\": tokenFollowType,\n      \"module\": tokenFollowType,\n      \"struct\": tokenFollowType,\n      \"lib\": tokenFollowType,\n      \"enum\": tokenFollowType,\n      \"union\": tokenFollowType\n    };\n    var matching = {\n      \"[\": \"]\",\n      \"{\": \"}\",\n      \"(\": \")\",\n      \"<\": \">\"\n    };\n\n    function tokenBase(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      } // Macros\n\n\n      if (state.lastToken != \"\\\\\" && stream.match(\"{%\", false)) {\n        return chain(tokenMacro(\"%\", \"%\"), stream, state);\n      }\n\n      if (state.lastToken != \"\\\\\" && stream.match(\"{{\", false)) {\n        return chain(tokenMacro(\"{\", \"}\"), stream, state);\n      } // Comments\n\n\n      if (stream.peek() == \"#\") {\n        stream.skipToEnd();\n        return \"comment\";\n      } // Variables and keywords\n\n\n      var matched;\n\n      if (stream.match(idents)) {\n        stream.eat(/[?!]/);\n        matched = stream.current();\n\n        if (stream.eat(\":\")) {\n          return \"atom\";\n        } else if (state.lastToken == \".\") {\n          return \"property\";\n        } else if (keywords.test(matched)) {\n          if (indentKeywords.test(matched)) {\n            if (!(matched == \"fun\" && state.blocks.indexOf(\"lib\") >= 0) && !(matched == \"def\" && state.lastToken == \"abstract\")) {\n              state.blocks.push(matched);\n              state.currentIndent += 1;\n            }\n          } else if ((state.lastStyle == \"operator\" || !state.lastStyle) && indentExpressionKeywords.test(matched)) {\n            state.blocks.push(matched);\n            state.currentIndent += 1;\n          } else if (matched == \"end\") {\n            state.blocks.pop();\n            state.currentIndent -= 1;\n          }\n\n          if (nextTokenizer.hasOwnProperty(matched)) {\n            state.tokenize.push(nextTokenizer[matched]);\n          }\n\n          return \"keyword\";\n        } else if (atomWords.test(matched)) {\n          return \"atom\";\n        }\n\n        return \"variable\";\n      } // Class variables and instance variables\n      // or attributes\n\n\n      if (stream.eat(\"@\")) {\n        if (stream.peek() == \"[\") {\n          return chain(tokenNest(\"[\", \"]\", \"meta\"), stream, state);\n        }\n\n        stream.eat(\"@\");\n        stream.match(idents) || stream.match(types);\n        return \"variable-2\";\n      } // Constants and types\n\n\n      if (stream.match(types)) {\n        return \"tag\";\n      } // Symbols or ':' operator\n\n\n      if (stream.eat(\":\")) {\n        if (stream.eat(\"\\\"\")) {\n          return chain(tokenQuote(\"\\\"\", \"atom\", false), stream, state);\n        } else if (stream.match(idents) || stream.match(types) || stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators)) {\n          return \"atom\";\n        }\n\n        stream.eat(\":\");\n        return \"operator\";\n      } // Strings\n\n\n      if (stream.eat(\"\\\"\")) {\n        return chain(tokenQuote(\"\\\"\", \"string\", true), stream, state);\n      } // Strings or regexps or macro variables or '%' operator\n\n\n      if (stream.peek() == \"%\") {\n        var style = \"string\";\n        var embed = true;\n        var delim;\n\n        if (stream.match(\"%r\")) {\n          // Regexps\n          style = \"string-2\";\n          delim = stream.next();\n        } else if (stream.match(\"%w\")) {\n          embed = false;\n          delim = stream.next();\n        } else if (stream.match(\"%q\")) {\n          embed = false;\n          delim = stream.next();\n        } else {\n          if (delim = stream.match(/^%([^\\w\\s=])/)) {\n            delim = delim[1];\n          } else if (stream.match(/^%[a-zA-Z0-9_\\u009F-\\uFFFF]*/)) {\n            // Macro variables\n            return \"meta\";\n          } else {\n            // '%' operator\n            return \"operator\";\n          }\n        }\n\n        if (matching.hasOwnProperty(delim)) {\n          delim = matching[delim];\n        }\n\n        return chain(tokenQuote(delim, style, embed), stream, state);\n      } // Here Docs\n\n\n      if (matched = stream.match(/^<<-('?)([A-Z]\\w*)\\1/)) {\n        return chain(tokenHereDoc(matched[2], !matched[1]), stream, state);\n      } // Characters\n\n\n      if (stream.eat(\"'\")) {\n        stream.match(/^(?:[^']|\\\\(?:[befnrtv0'\"]|[0-7]{3}|u(?:[0-9a-fA-F]{4}|\\{[0-9a-fA-F]{1,6}\\})))/);\n        stream.eat(\"'\");\n        return \"atom\";\n      } // Numbers\n\n\n      if (stream.eat(\"0\")) {\n        if (stream.eat(\"x\")) {\n          stream.match(/^[0-9a-fA-F]+/);\n        } else if (stream.eat(\"o\")) {\n          stream.match(/^[0-7]+/);\n        } else if (stream.eat(\"b\")) {\n          stream.match(/^[01]+/);\n        }\n\n        return \"number\";\n      }\n\n      if (stream.eat(/^\\d/)) {\n        stream.match(/^\\d*(?:\\.\\d+)?(?:[eE][+-]?\\d+)?/);\n        return \"number\";\n      } // Operators\n\n\n      if (stream.match(operators)) {\n        stream.eat(\"=\"); // Operators can follow assign symbol.\n\n        return \"operator\";\n      }\n\n      if (stream.match(conditionalOperators) || stream.match(anotherOperators)) {\n        return \"operator\";\n      } // Parens and braces\n\n\n      if (matched = stream.match(/[({[]/, false)) {\n        matched = matched[0];\n        return chain(tokenNest(matched, matching[matched], null), stream, state);\n      } // Escapes\n\n\n      if (stream.eat(\"\\\\\")) {\n        stream.next();\n        return \"meta\";\n      }\n\n      stream.next();\n      return null;\n    }\n\n    function tokenNest(begin, end, style, started) {\n      return function (stream, state) {\n        if (!started && stream.match(begin)) {\n          state.tokenize[state.tokenize.length - 1] = tokenNest(begin, end, style, true);\n          state.currentIndent += 1;\n          return style;\n        }\n\n        var nextStyle = tokenBase(stream, state);\n\n        if (stream.current() === end) {\n          state.tokenize.pop();\n          state.currentIndent -= 1;\n          nextStyle = style;\n        }\n\n        return nextStyle;\n      };\n    }\n\n    function tokenMacro(begin, end, started) {\n      return function (stream, state) {\n        if (!started && stream.match(\"{\" + begin)) {\n          state.currentIndent += 1;\n          state.tokenize[state.tokenize.length - 1] = tokenMacro(begin, end, true);\n          return \"meta\";\n        }\n\n        if (stream.match(end + \"}\")) {\n          state.currentIndent -= 1;\n          state.tokenize.pop();\n          return \"meta\";\n        }\n\n        return tokenBase(stream, state);\n      };\n    }\n\n    function tokenMacroDef(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      var matched;\n\n      if (matched = stream.match(idents)) {\n        if (matched == \"def\") {\n          return \"keyword\";\n        }\n\n        stream.eat(/[?!]/);\n      }\n\n      state.tokenize.pop();\n      return \"def\";\n    }\n\n    function tokenFollowIdent(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      if (stream.match(idents)) {\n        stream.eat(/[!?]/);\n      } else {\n        stream.match(operators) || stream.match(conditionalOperators) || stream.match(indexingOperators);\n      }\n\n      state.tokenize.pop();\n      return \"def\";\n    }\n\n    function tokenFollowType(stream, state) {\n      if (stream.eatSpace()) {\n        return null;\n      }\n\n      stream.match(types);\n      state.tokenize.pop();\n      return \"def\";\n    }\n\n    function tokenQuote(end, style, embed) {\n      return function (stream, state) {\n        var escaped = false;\n\n        while (stream.peek()) {\n          if (!escaped) {\n            if (stream.match(\"{%\", false)) {\n              state.tokenize.push(tokenMacro(\"%\", \"%\"));\n              return style;\n            }\n\n            if (stream.match(\"{{\", false)) {\n              state.tokenize.push(tokenMacro(\"{\", \"}\"));\n              return style;\n            }\n\n            if (embed && stream.match(\"#{\", false)) {\n              state.tokenize.push(tokenNest(\"#{\", \"}\", \"meta\"));\n              return style;\n            }\n\n            var ch = stream.next();\n\n            if (ch == end) {\n              state.tokenize.pop();\n              return style;\n            }\n\n            escaped = embed && ch == \"\\\\\";\n          } else {\n            stream.next();\n            escaped = false;\n          }\n        }\n\n        return style;\n      };\n    }\n\n    function tokenHereDoc(phrase, embed) {\n      return function (stream, state) {\n        if (stream.sol()) {\n          stream.eatSpace();\n\n          if (stream.match(phrase)) {\n            state.tokenize.pop();\n            return \"string\";\n          }\n        }\n\n        var escaped = false;\n\n        while (stream.peek()) {\n          if (!escaped) {\n            if (stream.match(\"{%\", false)) {\n              state.tokenize.push(tokenMacro(\"%\", \"%\"));\n              return \"string\";\n            }\n\n            if (stream.match(\"{{\", false)) {\n              state.tokenize.push(tokenMacro(\"{\", \"}\"));\n              return \"string\";\n            }\n\n            if (embed && stream.match(\"#{\", false)) {\n              state.tokenize.push(tokenNest(\"#{\", \"}\", \"meta\"));\n              return \"string\";\n            }\n\n            escaped = embed && stream.next() == \"\\\\\";\n          } else {\n            stream.next();\n            escaped = false;\n          }\n        }\n\n        return \"string\";\n      };\n    }\n\n    return {\n      startState: function startState() {\n        return {\n          tokenize: [tokenBase],\n          currentIndent: 0,\n          lastToken: null,\n          lastStyle: null,\n          blocks: []\n        };\n      },\n      token: function token(stream, state) {\n        var style = state.tokenize[state.tokenize.length - 1](stream, state);\n        var token = stream.current();\n\n        if (style && style != \"comment\") {\n          state.lastToken = token;\n          state.lastStyle = style;\n        }\n\n        return style;\n      },\n      indent: function indent(state, textAfter) {\n        textAfter = textAfter.replace(/^\\s*(?:\\{%)?\\s*|\\s*(?:%\\})?\\s*$/g, \"\");\n\n        if (dedentKeywords.test(textAfter) || dedentPunctuals.test(textAfter)) {\n          return config.indentUnit * (state.currentIndent - 1);\n        }\n\n        return config.indentUnit * state.currentIndent;\n      },\n      fold: \"indent\",\n      electricInput: wordRegExp(dedentPunctualsArray.concat(dedentKeywordsArray), true),\n      lineComment: '#'\n    };\n  });\n  CodeMirror.defineMIME(\"text/x-crystal\", \"crystal\");\n});","map":null,"metadata":{},"sourceType":"script"}